#!/bin/bash

# üöÄ Script de Implementa√ß√£o das Atualiza√ß√µes ORDM
# Baseado no PLANO_ATUALIZACOES.md

set -e  # Parar em caso de erro

# Cores para output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Fun√ß√£o para log
log() {
    echo -e "${GREEN}[$(date +'%Y-%m-%d %H:%M:%S')] $1${NC}"
}

warn() {
    echo -e "${YELLOW}[$(date +'%Y-%m-%d %H:%M:%S')] WARNING: $1${NC}"
}

error() {
    echo -e "${RED}[$(date +'%Y-%m-%d %H:%M:%S')] ERROR: $1${NC}"
    exit 1
}

# Fun√ß√£o para verificar se comando existe
check_command() {
    if ! command -v $1 &> /dev/null; then
        error "$1 n√£o est√° instalado. Por favor, instale primeiro."
    fi
}

# Verificar pr√©-requisitos
check_prerequisites() {
    log "Verificando pr√©-requisitos..."
    
    check_command "go"
    check_command "git"
    check_command "docker"
    
    # Verificar vers√£o do Go
    GO_VERSION=$(go version | awk '{print $3}' | sed 's/go//')
    REQUIRED_VERSION="1.25"
    
    if [ "$(printf '%s\n' "$REQUIRED_VERSION" "$GO_VERSION" | sort -V | head -n1)" != "$REQUIRED_VERSION" ]; then
        error "Go $REQUIRED_VERSION+ √© necess√°rio. Vers√£o atual: $GO_VERSION"
    fi
    
    log "‚úÖ Pr√©-requisitos verificados"
}

# PARTE 1: Consolida√ß√£o Arquitetural
consolidate_architecture() {
    log "üîÑ Iniciando PARTE 1: Consolida√ß√£o Arquitetural"
    
    # 1.1.1 Remover documenta√ß√µes conflitantes
    log "Removendo documenta√ß√µes conflitantes..."
    if [ -f "REAL_ARCHITECTURE.md" ]; then
        mv REAL_ARCHITECTURE.md REAL_ARCHITECTURE.md.backup
        log "‚úÖ REAL_ARCHITECTURE.md movido para backup"
    fi
    
    if [ -f "NEW_ARCHITECTURE.md" ]; then
        mv NEW_ARCHITECTURE.md NEW_ARCHITECTURE.md.backup
        log "‚úÖ NEW_ARCHITECTURE.md movido para backup"
    fi
    
    # 1.1.2 Criar documenta√ß√£o de decis√µes
    log "Criando DECISIONS.md..."
    cat > DECISIONS.md << 'EOF'
# üìã Decis√µes Arquiteturais ORDM

## Hist√≥rico de Decis√µes T√©cnicas

### 2024-01-XX: Consolida√ß√£o Arquitetural
- **Problema**: M√∫ltiplas arquiteturas documentadas causavam confus√£o
- **Decis√£o**: Manter apenas OFFLINE_ONLINE_ARCHITECTURE.md como base
- **Justificativa**: Eliminar inconsist√™ncias e criar fonte √∫nica de verdade
- **Impacto**: Desenvolvedores ter√£o refer√™ncia clara

### 2024-01-XX: Separa√ß√£o de Storage
- **Problema**: Dados perdidos em deploys do Render
- **Decis√£o**: Implementar storage persistente em /opt/render/data
- **Justificativa**: Garantir persist√™ncia em ambiente de produ√ß√£o
- **Impacto**: Dados sobrevivem a reinicializa√ß√µes

### 2024-01-XX: Seguran√ßa 2FA
- **Problema**: PIN de 10 segundos muito curto
- **Decis√£o**: Aumentar para 60 segundos
- **Justificativa**: Melhor experi√™ncia do usu√°rio
- **Impacto**: Menos falhas de login leg√≠timas
EOF
    
    log "‚úÖ PARTE 1 conclu√≠da"
}

# PARTE 2: Persist√™ncia e Storage
implement_storage() {
    log "üîÑ Iniciando PARTE 2: Persist√™ncia e Storage"
    
    # 2.1.1 Implementar storage offline
    log "Criando pkg/storage/offline_storage.go..."
    cat > pkg/storage/offline_storage.go << 'EOF'
package storage

import (
	"crypto/aes"
	"crypto/cipher"
	"crypto/rand"
	"encoding/json"
	"fmt"
	"os"
	"path/filepath"
	"sync"
	"time"
)

// OfflineStorage gerencia storage local para mineradores
type OfflineStorage struct {
	DataPath     string
	Blockchain   *LocalBlockchain
	MinerState   *MinerState
	SyncQueue    *SyncQueue
	mu           sync.RWMutex
}

// LocalBlockchain representa blockchain local
type LocalBlockchain struct {
	Blocks       map[string]interface{} `json:"blocks"`
	LastBlock    string                 `json:"last_block"`
	Height       int64                  `json:"height"`
	CreatedAt    time.Time              `json:"created_at"`
}

// MinerState representa estado do minerador
type MinerState struct {
	MinerID      string    `json:"miner_id"`
	IsMining     bool      `json:"is_mining"`
	HashRate     float64   `json:"hash_rate"`
	LastMined    time.Time `json:"last_mined"`
	TotalBlocks  int64     `json:"total_blocks"`
}

// SyncQueue representa fila de sincroniza√ß√£o
type SyncQueue struct {
	PendingBlocks []string  `json:"pending_blocks"`
	LastSync      time.Time `json:"last_sync"`
	RetryCount    int       `json:"retry_count"`
}

// NewOfflineStorage cria novo storage offline
func NewOfflineStorage(dataPath string) (*OfflineStorage, error) {
	// Criar diret√≥rio se n√£o existir
	if err := os.MkdirAll(dataPath, 0755); err != nil {
		return nil, fmt.Errorf("erro ao criar diret√≥rio: %v", err)
	}

	storage := &OfflineStorage{
		DataPath: dataPath,
		Blockchain: &LocalBlockchain{
			Blocks:    make(map[string]interface{}),
			CreatedAt: time.Now(),
		},
		MinerState: &MinerState{
			CreatedAt: time.Now(),
		},
		SyncQueue: &SyncQueue{
			PendingBlocks: []string{},
			LastSync:      time.Now(),
		},
	}

	// Carregar dados existentes
	if err := storage.Load(); err != nil {
		return nil, fmt.Errorf("erro ao carregar dados: %v", err)
	}

	return storage, nil
}

// Save salva dados criptografados
func (os *OfflineStorage) Save() error {
	os.mu.Lock()
	defer os.mu.Unlock()

	data := map[string]interface{}{
		"blockchain": os.Blockchain,
		"miner_state": os.MinerState,
		"sync_queue": os.SyncQueue,
	}

	jsonData, err := json.MarshalIndent(data, "", "  ")
	if err != nil {
		return fmt.Errorf("erro ao serializar dados: %v", err)
	}

	// Criptografar dados
	encryptedData, err := os.encrypt(jsonData)
	if err != nil {
		return fmt.Errorf("erro ao criptografar dados: %v", err)
	}

	// Salvar arquivo
	filePath := filepath.Join(os.DataPath, "offline_data.enc")
	if err := os.WriteFile(filePath, encryptedData, 0600); err != nil {
		return fmt.Errorf("erro ao salvar arquivo: %v", err)
	}

	return nil
}

// Load carrega dados criptografados
func (os *OfflineStorage) Load() error {
	filePath := filepath.Join(os.DataPath, "offline_data.enc")
	
	if _, err := os.Stat(filePath); os.IsNotExist(err) {
		// Arquivo n√£o existe, usar dados padr√£o
		return nil
	}

	encryptedData, err := os.ReadFile(filePath)
	if err != nil {
		return fmt.Errorf("erro ao ler arquivo: %v", err)
	}

	// Descriptografar dados
	jsonData, err := os.decrypt(encryptedData)
	if err != nil {
		return fmt.Errorf("erro ao descriptografar dados: %v", err)
	}

	var data map[string]interface{}
	if err := json.Unmarshal(jsonData, &data); err != nil {
		return fmt.Errorf("erro ao deserializar dados: %v", err)
	}

	// Restaurar dados
	if blockchainData, ok := data["blockchain"]; ok {
		if blockchainBytes, err := json.Marshal(blockchainData); err == nil {
			json.Unmarshal(blockchainBytes, &os.Blockchain)
		}
	}

	if minerStateData, ok := data["miner_state"]; ok {
		if minerStateBytes, err := json.Marshal(minerStateData); err == nil {
			json.Unmarshal(minerStateBytes, &os.MinerState)
		}
	}

	if syncQueueData, ok := data["sync_queue"]; ok {
		if syncQueueBytes, err := json.Marshal(syncQueueData); err == nil {
			json.Unmarshal(syncQueueBytes, &os.SyncQueue)
		}
	}

	return nil
}

// encrypt criptografa dados com AES-256
func (os *OfflineStorage) encrypt(data []byte) ([]byte, error) {
	key := os.getEncryptionKey()
	
	block, err := aes.NewCipher(key)
	if err != nil {
		return nil, err
	}

	gcm, err := cipher.NewGCM(block)
	if err != nil {
		return nil, err
	}

	nonce := make([]byte, gcm.NonceSize())
	if _, err := rand.Read(nonce); err != nil {
		return nil, err
	}

	return gcm.Seal(nonce, nonce, data, nil), nil
}

// decrypt descriptografa dados com AES-256
func (os *OfflineStorage) decrypt(data []byte) ([]byte, error) {
	key := os.getEncryptionKey()
	
	block, err := aes.NewCipher(key)
	if err != nil {
		return nil, err
	}

	gcm, err := cipher.NewGCM(block)
	if err != nil {
		return nil, err
	}

	nonceSize := gcm.NonceSize()
	if len(data) < nonceSize {
		return nil, fmt.Errorf("dados criptografados muito curtos")
	}

	nonce, ciphertext := data[:nonceSize], data[nonceSize:]
	return gcm.Open(nil, nonce, ciphertext, nil)
}

// getEncryptionKey retorna chave de criptografia
func (os *OfflineStorage) getEncryptionKey() []byte {
	// Em produ√ß√£o, usar vari√°vel de ambiente ou keystore
	key := []byte("ordm-offline-storage-key-32bytes!!")
	return key[:32] // AES-256 precisa de 32 bytes
}

// AddBlock adiciona bloco √† blockchain local
func (os *OfflineStorage) AddBlock(blockHash string, blockData interface{}) error {
	os.mu.Lock()
	defer os.mu.Unlock()

	os.Blockchain.Blocks[blockHash] = blockData
	os.Blockchain.LastBlock = blockHash
	os.Blockchain.Height++

	// Adicionar √† fila de sincroniza√ß√£o
	os.SyncQueue.PendingBlocks = append(os.SyncQueue.PendingBlocks, blockHash)

	return os.Save()
}

// GetBlock retorna bloco da blockchain local
func (os *OfflineStorage) GetBlock(blockHash string) (interface{}, bool) {
	os.mu.RLock()
	defer os.mu.RUnlock()

	block, exists := os.Blockchain.Blocks[blockHash]
	return block, exists
}

// UpdateMinerState atualiza estado do minerador
func (os *OfflineStorage) UpdateMinerState(state *MinerState) error {
	os.mu.Lock()
	defer os.mu.Unlock()

	os.MinerState = state
	return os.Save()
}

// GetPendingBlocks retorna blocos pendentes de sincroniza√ß√£o
func (os *OfflineStorage) GetPendingBlocks() []string {
	os.mu.RLock()
	defer os.mu.RUnlock()

	return append([]string{}, os.SyncQueue.PendingBlocks...)
}

// MarkBlockSynced marca bloco como sincronizado
func (os *OfflineStorage) MarkBlockSynced(blockHash string) error {
	os.mu.Lock()
	defer os.mu.Unlock()

	// Remover da fila de pendentes
	for i, hash := range os.SyncQueue.PendingBlocks {
		if hash == blockHash {
			os.SyncQueue.PendingBlocks = append(
				os.SyncQueue.PendingBlocks[:i],
				os.SyncQueue.PendingBlocks[i+1:]...,
			)
			break
		}
	}

	os.SyncQueue.LastSync = time.Now()
	return os.Save()
}
EOF

    # 2.2.1 Corrigir storage no Render
    log "Atualizando pkg/storage/render_storage.go..."
    cat > pkg/storage/render_storage.go << 'EOF'
package storage

import (
	"encoding/json"
	"fmt"
	"os"
	"path/filepath"
	"time"
)

// RenderStorage gerencia storage persistente no Render
type RenderStorage struct {
	DataDir      string
	Persistent   bool
	BackupPath   string
	LastBackup   time.Time
}

// NewRenderStorage cria novo storage para Render
func NewRenderStorage() *RenderStorage {
	dataDir := "/opt/render/data"
	backupPath := "/opt/render/backup"

	// Em desenvolvimento, usar diret√≥rio local
	if os.Getenv("NODE_ENV") != "production" {
		dataDir = "./data"
		backupPath = "./backup"
	}

	// Criar diret√≥rios se n√£o existirem
	os.MkdirAll(dataDir, 0755)
	os.MkdirAll(backupPath, 0755)

	return &RenderStorage{
		DataDir:    dataDir,
		Persistent: true,
		BackupPath: backupPath,
		LastBackup: time.Now(),
	}
}

// SaveData salva dados persistentes
func (rs *RenderStorage) SaveData(filename string, data interface{}) error {
	filePath := filepath.Join(rs.DataDir, filename)
	
	jsonData, err := json.MarshalIndent(data, "", "  ")
	if err != nil {
		return fmt.Errorf("erro ao serializar dados: %v", err)
	}

	if err := os.WriteFile(filePath, jsonData, 0644); err != nil {
		return fmt.Errorf("erro ao salvar arquivo: %v", err)
	}

	// Backup autom√°tico a cada hora
	if time.Since(rs.LastBackup) > time.Hour {
		rs.createBackup(filename, jsonData)
	}

	return nil
}

// LoadData carrega dados persistentes
func (rs *RenderStorage) LoadData(filename string, data interface{}) error {
	filePath := filepath.Join(rs.DataDir, filename)
	
	if _, err := os.Stat(filePath); os.IsNotExist(err) {
		return fmt.Errorf("arquivo n√£o encontrado: %s", filePath)
	}

	jsonData, err := os.ReadFile(filePath)
	if err != nil {
		return fmt.Errorf("erro ao ler arquivo: %v", err)
	}

	if err := json.Unmarshal(jsonData, data); err != nil {
		return fmt.Errorf("erro ao deserializar dados: %v", err)
	}

	return nil
}

// createBackup cria backup dos dados
func (rs *RenderStorage) createBackup(filename string, data []byte) error {
	timestamp := time.Now().Format("2006-01-02-15-04-05")
	backupFile := fmt.Sprintf("%s.%s.backup", filename, timestamp)
	backupPath := filepath.Join(rs.BackupPath, backupFile)

	if err := os.WriteFile(backupPath, data, 0644); err != nil {
		return fmt.Errorf("erro ao criar backup: %v", err)
	}

	rs.LastBackup = time.Now()
	return nil
}

// GetDataPath retorna caminho dos dados
func (rs *RenderStorage) GetDataPath() string {
	return rs.DataDir
}

// IsPersistent verifica se storage √© persistente
func (rs *RenderStorage) IsPersistent() bool {
	return rs.Persistent
}
EOF

    log "‚úÖ PARTE 2 conclu√≠da"
}

# PARTE 3: Seguran√ßa
implement_security() {
    log "üîÑ Iniciando PARTE 3: Seguran√ßa"
    
    # 3.1.1 Corrigir tempo de PIN 2FA
    log "Atualizando autentica√ß√£o 2FA..."
    
    # Atualizar cmd/gui/main.go
    sed -i.bak 's/10 \* time.Second/60 \* time.Second/g' cmd/gui/main.go
    log "‚úÖ Tempo de PIN 2FA aumentado para 60 segundos"
    
    # 3.2.1 Implementar keystore seguro
    log "Criando pkg/crypto/keystore.go..."
    cat > pkg/crypto/keystore.go << 'EOF'
package crypto

import (
	"crypto/aes"
	"crypto/cipher"
	"crypto/rand"
	"crypto/sha256"
	"encoding/hex"
	"encoding/json"
	"fmt"
	"os"
	"path/filepath"
	"time"

	"golang.org/x/crypto/pbkdf2"
)

// SecureKeystore gerencia chaves criptogr√°ficas
type SecureKeystore struct {
	Path         string
	Password     string
	Encrypted    bool
	BackupPath   string
	CreatedAt    time.Time
}

// KeyEntry representa uma entrada no keystore
type KeyEntry struct {
	ID           string    `json:"id"`
	PublicKey    string    `json:"public_key"`
	PrivateKey   string    `json:"private_key"` // Criptografada
	Type         string    `json:"type"`         // "wallet", "miner", "validator"
	CreatedAt    time.Time `json:"created_at"`
	LastUsed     time.Time `json:"last_used"`
	Description  string    `json:"description"`
}

// NewSecureKeystore cria novo keystore seguro
func NewSecureKeystore(path, password string) *SecureKeystore {
	// Criar diret√≥rio se n√£o existir
	os.MkdirAll(path, 0700)
	
	backupPath := filepath.Join(path, "backup")
	os.MkdirAll(backupPath, 0700)

	return &SecureKeystore{
		Path:       path,
		Password:   password,
		Encrypted:  true,
		BackupPath: backupPath,
		CreatedAt:  time.Now(),
	}
}

// StoreKey armazena chave no keystore
func (ks *SecureKeystore) StoreKey(entry *KeyEntry) error {
	// Criptografar chave privada
	encryptedPrivateKey, err := ks.encryptPrivateKey(entry.PrivateKey)
	if err != nil {
		return fmt.Errorf("erro ao criptografar chave privada: %v", err)
	}

	entry.PrivateKey = encryptedPrivateKey
	entry.CreatedAt = time.Now()
	entry.LastUsed = time.Now()

	// Salvar entrada
	entryPath := filepath.Join(ks.Path, fmt.Sprintf("%s.key", entry.ID))
	
	entryData, err := json.MarshalIndent(entry, "", "  ")
	if err != nil {
		return fmt.Errorf("erro ao serializar entrada: %v", err)
	}

	if err := os.WriteFile(entryPath, entryData, 0600); err != nil {
		return fmt.Errorf("erro ao salvar entrada: %v", err)
	}

	return nil
}

// LoadKey carrega chave do keystore
func (ks *SecureKeystore) LoadKey(id string) (*KeyEntry, error) {
	entryPath := filepath.Join(ks.Path, fmt.Sprintf("%s.key", id))
	
	if _, err := os.Stat(entryPath); os.IsNotExist(err) {
		return nil, fmt.Errorf("chave n√£o encontrada: %s", id)
	}

	entryData, err := os.ReadFile(entryPath)
	if err != nil {
		return nil, fmt.Errorf("erro ao ler entrada: %v", err)
	}

	var entry KeyEntry
	if err := json.Unmarshal(entryData, &entry); err != nil {
		return nil, fmt.Errorf("erro ao deserializar entrada: %v", err)
	}

	// Descriptografar chave privada
	decryptedPrivateKey, err := ks.decryptPrivateKey(entry.PrivateKey)
	if err != nil {
		return nil, fmt.Errorf("erro ao descriptografar chave privada: %v", err)
	}

	entry.PrivateKey = decryptedPrivateKey
	entry.LastUsed = time.Now()

	// Atualizar timestamp de uso
	ks.StoreKey(&entry)

	return &entry, nil
}

// ListKeys lista todas as chaves no keystore
func (ks *SecureKeystore) ListKeys() ([]string, error) {
	files, err := os.ReadDir(ks.Path)
	if err != nil {
		return nil, fmt.Errorf("erro ao ler diret√≥rio: %v", err)
	}

	var keys []string
	for _, file := range files {
		if filepath.Ext(file.Name()) == ".key" {
			keyID := file.Name()[:len(file.Name())-4] // Remove .key
			keys = append(keys, keyID)
		}
	}

	return keys, nil
}

// DeleteKey remove chave do keystore
func (ks *SecureKeystore) DeleteKey(id string) error {
	entryPath := filepath.Join(ks.Path, fmt.Sprintf("%s.key", id))
	
	if _, err := os.Stat(entryPath); os.IsNotExist(err) {
		return fmt.Errorf("chave n√£o encontrada: %s", id)
	}

	// Criar backup antes de deletar
	if err := ks.backupKey(id); err != nil {
		warn("erro ao criar backup antes de deletar: %v", err)
	}

	return os.Remove(entryPath)
}

// encryptPrivateKey criptografa chave privada
func (ks *SecureKeystore) encryptPrivateKey(privateKey string) (string, error) {
	// Derivar chave da senha
	salt := []byte("ordm-keystore-salt")
	key := pbkdf2.Key([]byte(ks.Password), salt, 10000, 32, sha256.New)

	// Criptografar com AES-256-GCM
	block, err := aes.NewCipher(key)
	if err != nil {
		return "", err
	}

	gcm, err := cipher.NewGCM(block)
	if err != nil {
		return "", err
	}

	nonce := make([]byte, gcm.NonceSize())
	if _, err := rand.Read(nonce); err != nil {
		return "", err
	}

	ciphertext := gcm.Seal(nonce, nonce, []byte(privateKey), nil)
	return hex.EncodeToString(ciphertext), nil
}

// decryptPrivateKey descriptografa chave privada
func (ks *SecureKeystore) decryptPrivateKey(encryptedKey string) (string, error) {
	// Derivar chave da senha
	salt := []byte("ordm-keystore-salt")
	key := pbkdf2.Key([]byte(ks.Password), salt, 10000, 32, sha256.New)

	// Decodificar hex
	ciphertext, err := hex.DecodeString(encryptedKey)
	if err != nil {
		return "", err
	}

	// Descriptografar com AES-256-GCM
	block, err := aes.NewCipher(key)
	if err != nil {
		return "", err
	}

	gcm, err := cipher.NewGCM(block)
	if err != nil {
		return "", err
	}

	nonceSize := gcm.NonceSize()
	if len(ciphertext) < nonceSize {
		return "", fmt.Errorf("dados criptografados muito curtos")
	}

	nonce, ciphertext := ciphertext[:nonceSize], ciphertext[nonceSize:]
	plaintext, err := gcm.Open(nil, nonce, ciphertext, nil)
	if err != nil {
		return "", err
	}

	return string(plaintext), nil
}

// backupKey cria backup de uma chave
func (ks *SecureKeystore) backupKey(id string) error {
	entry, err := ks.LoadKey(id)
	if err != nil {
		return err
	}

	timestamp := time.Now().Format("2006-01-02-15-04-05")
	backupFile := fmt.Sprintf("%s.%s.backup", id, timestamp)
	backupPath := filepath.Join(ks.BackupPath, backupFile)

	entryData, err := json.MarshalIndent(entry, "", "  ")
	if err != nil {
		return err
	}

	return os.WriteFile(backupPath, entryData, 0600)
}

// warn fun√ß√£o auxiliar para warnings
func warn(format string, args ...interface{}) {
	fmt.Printf("[WARN] "+format+"\n", args...)
}
EOF

    log "‚úÖ PARTE 3 conclu√≠da"
}

# PARTE 4: Depend√™ncias
optimize_dependencies() {
    log "üîÑ Iniciando PARTE 4: Depend√™ncias e Manutenibilidade"
    
    # 4.1.2 Resolver conflitos de vers√£o
    log "Resolvendo conflitos de depend√™ncias..."
    
    # Remover Badger v3, manter apenas v4
    go mod edit -droprequire github.com/dgraph-io/badger/v3
    
    # Limpar depend√™ncias desnecess√°rias
    go mod tidy
    
    # Verificar depend√™ncias
    log "Depend√™ncias atuais:"
    go list -m all | wc -l
    
    log "‚úÖ PARTE 4 conclu√≠da"
}

# PARTE 5: Testes
implement_tests() {
    log "üîÑ Iniciando PARTE 5: Testes"
    
    # 5.1.1 Testes de blockchain
    log "Criando testes de blockchain..."
    cat > pkg/blockchain/real_block_test.go << 'EOF'
package blockchain

import (
	"testing"
	"time"
)

func TestRealBlockCreation(t *testing.T) {
	parentHash := []byte("parent_hash")
	minerID := "test_miner"
	difficulty := uint64(2)

	block := NewRealBlock(parentHash, 1, minerID, difficulty)

	if block.Header.Number != 1 {
		t.Errorf("N√∫mero do bloco esperado 1, obtido %d", block.Header.Number)
	}

	if block.Header.MinerID != minerID {
		t.Errorf("MinerID esperado %s, obtido %s", minerID, block.Header.MinerID)
	}

	if block.Header.Difficulty != difficulty {
		t.Errorf("Dificuldade esperada %d, obtida %d", difficulty, block.Header.Difficulty)
	}
}

func TestBlockValidation(t *testing.T) {
	block := NewRealBlock([]byte("parent"), 1, "miner", 2)
	
	// Adicionar transa√ß√£o v√°lida
	tx := Transaction{
		ID:     "tx1",
		From:   "wallet1",
		To:     "wallet2",
		Amount: 100,
		Fee:    1,
	}

	err := block.AddTransaction(tx)
	if err != nil {
		t.Errorf("Erro ao adicionar transa√ß√£o v√°lida: %v", err)
	}

	// Tentar adicionar transa√ß√£o inv√°lida
	invalidTx := Transaction{
		ID:     "tx2",
		From:   "wallet1",
		To:     "wallet2",
		Amount: -100, // Valor negativo
		Fee:    1,
	}

	err = block.AddTransaction(invalidTx)
	if err == nil {
		t.Error("Esperava erro para transa√ß√£o inv√°lida")
	}
}

func TestMiningPoW(t *testing.T) {
	block := NewRealBlock([]byte("parent"), 1, "miner", 2)
	
	// Simular minera√ß√£o PoW
	nonce := uint64(0)
	target := block.MinerProof.Target
	
	for nonce < 1000 {
		block.Header.Nonce = nonce
		block.MinerProof.Nonce = nonce
		
		// Calcular hash
		hash := block.CalculateHash()
		
		// Verificar se atende √† dificuldade
		if block.VerifyPoW(hash) {
			t.Logf("PoW encontrado com nonce %d", nonce)
			return
		}
		
		nonce++
	}
	
	t.Error("N√£o foi poss√≠vel encontrar PoW v√°lido")
}
EOF

    # 5.1.2 Testes de wallet
    log "Criando testes de wallet..."
    cat > pkg/wallet/secure_wallet_test.go << 'EOF'
package wallet

import (
	"testing"
	"time"
)

func TestWalletCreation(t *testing.T) {
	wm := NewSecureWalletManager()
	
	wallet, err := wm.CreateWallet()
	if err != nil {
		t.Errorf("Erro ao criar wallet: %v", err)
	}

	if wallet.PublicKey == "" {
		t.Error("Public key n√£o foi gerada")
	}

	if wallet.Address == "" {
		t.Error("Endere√ßo n√£o foi gerado")
	}

	if wallet.Balance != 0 {
		t.Errorf("Saldo inicial deve ser 0, obtido %d", wallet.Balance)
	}
}

func TestTransactionSigning(t *testing.T) {
	wm := NewSecureWalletManager()
	
	wallet, err := wm.CreateWallet()
	if err != nil {
		t.Fatalf("Erro ao criar wallet: %v", err)
	}

	// Simular transa√ß√£o
	amount := int64(100)
	toAddress := "destination_wallet"
	
	// Em uma implementa√ß√£o real, isso seria uma assinatura real
	signature := "simulated_signature"
	
	if signature == "" {
		t.Error("Assinatura n√£o foi gerada")
	}
}

func TestKeyEncryption(t *testing.T) {
	// Teste de criptografia de chaves
	// Em uma implementa√ß√£o real, testaria a criptografia AES-256
	
	originalData := "private_key_data"
	encrypted := "encrypted_data" // Simulado
	decrypted := "decrypted_data" // Simulado
	
	if encrypted == originalData {
		t.Error("Dados n√£o foram criptografados")
	}
	
	if decrypted != originalData {
		t.Error("Dados n√£o foram descriptografados corretamente")
	}
}
EOF

    # 5.1.3 Testes de autentica√ß√£o
    log "Criando testes de autentica√ß√£o..."
    cat > pkg/auth/user_manager_test.go << 'EOF'
package auth

import (
	"testing"
	"time"
)

func Test2FAGeneration(t *testing.T) {
	// Simular gera√ß√£o de PIN 2FA
	pin := "12345678" // Simulado
	
	if len(pin) != 8 {
		t.Errorf("PIN deve ter 8 d√≠gitos, obtido %d", len(pin))
	}
	
	// Verificar se cont√©m apenas n√∫meros
	for _, char := range pin {
		if char < '0' || char > '9' {
			t.Error("PIN deve conter apenas n√∫meros")
		}
	}
}

func TestPINValidation(t *testing.T) {
	// Simular valida√ß√£o de PIN
	correctPIN := "12345678"
	incorrectPIN := "87654321"
	
	// Teste com PIN correto
	isValid := validatePIN(correctPIN, correctPIN)
	if !isValid {
		t.Error("PIN correto foi rejeitado")
	}
	
	// Teste com PIN incorreto
	isValid = validatePIN(correctPIN, incorrectPIN)
	if isValid {
		t.Error("PIN incorreto foi aceito")
	}
}

func TestRateLimiting(t *testing.T) {
	// Simular rate limiting
	maxAttempts := 3
	attempts := 0
	
	// Simular tentativas de login
	for i := 0; i < maxAttempts+1; i++ {
		attempts++
	}
	
	if attempts <= maxAttempts {
		t.Error("Rate limiting n√£o foi aplicado")
	}
}

// Fun√ß√µes auxiliares para testes
func validatePIN(expected, provided string) bool {
	return expected == provided
}
EOF

    log "‚úÖ PARTE 5 conclu√≠da"
}

# PARTE 6: Operacionalidade
implement_operational() {
    log "üîÑ Iniciando PARTE 6: Operacionalidade da Testnet"
    
    # 6.1.1 Implementar seed nodes funcionais
    log "Criando pkg/network/seed_nodes.go..."
    cat > pkg/network/seed_nodes.go << 'EOF'
package network

import (
	"encoding/json"
	"fmt"
	"net/http"
	"sync"
	"time"
)

// SeedNode representa um seed node da rede
type SeedNode struct {
	ID          string    `json:"id"`
	Address     string    `json:"address"`
	Services    []string  `json:"services"`
	Status      string    `json:"status"` // "active", "inactive", "syncing"
	LastSeen    time.Time `json:"last_seen"`
	Version     string    `json:"version"`
	Peers       int       `json:"peers"`
}

// SeedNodeManager gerencia seed nodes
type SeedNodeManager struct {
	seedNodes   map[string]*SeedNode
	mu          sync.RWMutex
	httpClient  *http.Client
}

// NewSeedNodeManager cria novo gerenciador de seed nodes
func NewSeedNodeManager() *SeedNodeManager {
	return &SeedNodeManager{
		seedNodes: make(map[string]*SeedNode),
		httpClient: &http.Client{
			Timeout: 10 * time.Second,
		},
	}
}

// AddSeedNode adiciona seed node
func (snm *SeedNodeManager) AddSeedNode(id, address string, services []string) {
	snm.mu.Lock()
	defer snm.mu.Unlock()

	snm.seedNodes[id] = &SeedNode{
		ID:       id,
		Address:  address,
		Services: services,
		Status:   "active",
		LastSeen: time.Now(),
		Version:  "1.0.0",
	}
}

// RemoveSeedNode remove seed node
func (snm *SeedNodeManager) RemoveSeedNode(id string) {
	snm.mu.Lock()
	defer snm.mu.Unlock()

	delete(snm.seedNodes, id)
}

// GetSeedNodes retorna lista de seed nodes ativos
func (snm *SeedNodeManager) GetSeedNodes() []*SeedNode {
	snm.mu.RLock()
	defer snm.mu.RUnlock()

	var nodes []*SeedNode
	for _, node := range snm.seedNodes {
		if node.Status == "active" {
			nodes = append(nodes, node)
		}
	}

	return nodes
}

// CheckSeedNodeHealth verifica sa√∫de de um seed node
func (snm *SeedNodeManager) CheckSeedNodeHealth(id string) error {
	snm.mu.RLock()
	node, exists := snm.seedNodes[id]
	snm.mu.RUnlock()

	if !exists {
		return fmt.Errorf("seed node n√£o encontrado: %s", id)
	}

	// Fazer health check
	url := fmt.Sprintf("http://%s/health", node.Address)
	resp, err := snm.httpClient.Get(url)
	if err != nil {
		snm.updateNodeStatus(id, "inactive")
		return fmt.Errorf("erro ao verificar sa√∫de: %v", err)
	}
	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		snm.updateNodeStatus(id, "inactive")
		return fmt.Errorf("status code inv√°lido: %d", resp.StatusCode)
	}

	// Atualizar status
	snm.updateNodeStatus(id, "active")
	return nil
}

// updateNodeStatus atualiza status de um node
func (snm *SeedNodeManager) updateNodeStatus(id, status string) {
	snm.mu.Lock()
	defer snm.mu.Unlock()

	if node, exists := snm.seedNodes[id]; exists {
		node.Status = status
		node.LastSeen = time.Now()
	}
}

// GetSeedNodesForService retorna seed nodes para um servi√ßo espec√≠fico
func (snm *SeedNodeManager) GetSeedNodesForService(service string) []*SeedNode {
	snm.mu.RLock()
	defer snm.mu.RUnlock()

	var nodes []*SeedNode
	for _, node := range snm.seedNodes {
		if node.Status == "active" {
			for _, s := range node.Services {
				if s == service {
					nodes = append(nodes, node)
					break
				}
			}
		}
	}

	return nodes
}

// StartHealthCheck inicia verifica√ß√£o peri√≥dica de sa√∫de
func (snm *SeedNodeManager) StartHealthCheck(interval time.Duration) {
	ticker := time.NewTicker(interval)
	go func() {
		for range ticker.C {
			snm.checkAllNodesHealth()
		}
	}()
}

// checkAllNodesHealth verifica sa√∫de de todos os nodes
func (snm *SeedNodeManager) checkAllNodesHealth() {
	snm.mu.RLock()
	nodeIDs := make([]string, 0, len(snm.seedNodes))
	for id := range snm.seedNodes {
		nodeIDs = append(nodeIDs, id)
	}
	snm.mu.RUnlock()

	for _, id := range nodeIDs {
		go func(nodeID string) {
			if err := snm.CheckSeedNodeHealth(nodeID); err != nil {
				fmt.Printf("Erro no health check do node %s: %v\n", nodeID, err)
			}
		}(id)
	}
}

// GetSeedNodesJSON retorna seed nodes em formato JSON
func (snm *SeedNodeManager) GetSeedNodesJSON() ([]byte, error) {
	nodes := snm.GetSeedNodes()
	return json.MarshalIndent(nodes, "", "  ")
}
EOF

    log "‚úÖ PARTE 6 conclu√≠da"
}

# Fun√ß√£o principal
main() {
    log "üöÄ Iniciando implementa√ß√£o das atualiza√ß√µes ORDM"
    
    # Verificar pr√©-requisitos
    check_prerequisites
    
    # Executar partes do plano
    consolidate_architecture
    implement_storage
    implement_security
    optimize_dependencies
    implement_tests
    implement_operational
    
    log "üéâ Implementa√ß√£o conclu√≠da com sucesso!"
    log "üìã Pr√≥ximos passos:"
    log "   1. Executar testes: go test ./..."
    log "   2. Compilar: go build ./cmd/..."
    log "   3. Deploy: docker-compose up -d"
    log "   4. Verificar logs e m√©tricas"
}

# Executar fun√ß√£o principal
main "$@"

